---
title: "Alexander_Klueber_signalling_through_websites"
author: "Alexander Klueber"
date: "4/7/2020"
output: bookdown::pdf_document2
bibliography: Bibliography.bib
citations: natbib
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::write_bib(c("blei", "cai", "horsley", "jiang", "un", "seifert", "pan"), "Bibliography.bib", width = 60)

library(viridis)
library(hrbrthemes)
library(ggridges)
library(skimr)
library(tidybayes)
library(rstanarm)
library(tidyverse)
library(stargazer)
library(tinytex)
library(gtable)
library(gt)


```

# Replication and extension of How Chinese Officials Use the Internet to Construct their Public Image

## Abstract

Pan shows that the emphasis on Chinese local government websites on either the competence or benevolence of county executives depends on where they are in the political tenure cycle. Early tenure county executives project images of benevolence by emphasizing their attentiveness and concern toward citizens. Late tenure executives project images of competence by highlighting their achievements. These findings shift the nature of debates concerning the role of the Internet in authoritarian regimes from a focus on regime-society
interactions to an examination of dynamics among regime insiders. I was largely able to replicate the statistical models that she uses to suggest the before mentioned relationship between county level executives and government websites. My own extension confirms that this is the most likely explanation for the observed effect by introducing a series of new models that could support alternative explanations for the observed effect (cultural differences, gender differences, etc.) and comparing the explanatory power of these models through the leave one out method. In addition I could validate the randomness of the sample selected to draw the underlying conclusions from a geographical perspective through a repeated sampling simulation and the construction of confidence intervals and their comparison with the observed provinces in the sample.

## Introduction 

I am interested to explore whether other explanations than the signalling function within authoritarian regimes may plosibly exlain the alterations in competence / benevolence patterns described in the paper. I will explore these alternatives by comparing the explanatory power of the variable categories employed in the paper and extending them with a new category (culture which will include the macro-region and the county type). Alternative hypothesis therefore are:
1. The benevolence/competence patterns may be explained by regional cultural variations
2. The benevolence/competence patterns may be explained by the resources at disposal to the official
3. The benevolence/competence patterns may be explained by internal peer preferences  
4. The benevolence/competence patterns may be explained by characteristics of the prefecture 
5. The benevolence/competence patterns may be explained by the individual abilities of the county officials
6. The benevolence/competence patterns may be explained by the immediate career success of county officials

Proving that it is in fact not tenure, but one of the other factors that have nothing to do with the career path of the individuals within the party, would weaken that connection. This comparison between models seems relevant as in the original paper the variables that are statistically significant vary between the various models. In the model with the most controls, for competence mayor education levels and whether a county party secretary is in first year of office are statistically significant, for benevolence no variables are statistically significant. Between the regressions the number of observations included also varies, which adds an additional compounding factor that makes a comparison between the models and the variables in the models difficult.  

This endevour is constrained by the data available in the dataverse associated to the replication paper. Only the pre-selected sample of 100 contains all variables relevant for the analysis on a county level. Therefore a sub-division of that data by provinces will leave us with very small sample sizes. Other examples are that the sample only contains 4 female mayors, 1 person with education level 6, 4 people with education level 5, 3 people with education levle 2 and 2 people with education level 0.  

Building on this, the other part of my extension will be around validating the sample selection process. It seems very surprising that the author has sub-selected 100 of the 2,787 counties with website, and we immediately dismiss another ~30 in our regressions because of data inavailability and subsequently another ~20 as our regressions get more ambitious and include more variables. The absence of any website from Tibet is furthermore conspicuous. The way by which I seek to challenge this is to compare the observed characteristics of the sample, to what we would expect in repeated sampling from the underlying population in terms of frequency of different provinces and in terms of data availability. This will allow us do deduct how representative the sample actually is for the underlying population. Significant deviances will have us question the validity of the sampling procedure and as a result the conclusions drawn by the author based on that sample. The only dimension in which this is possible is in regards to provinces as they are available for the population and the sample.    

## Literature review

## Comparison of ideal regression models in explaining competence and benevolence 

One challenge with the regressions is that they are actually based on different underlying data. This is because of the data availability in the sample of 100 counties and then the prediction file. As we employ the various regressions, the number of observations used to fit these regressions decreases from 71 to 48. They are therefore fit based on different underlying data.

In a first step I therefore harmonize the regressions by basing them on the same number of observations throughout - the 48 observations that have all data available. I then compare whether the new regressions yield similar results as the regressions in the paper.

### Competence 
```{r regression_comparison_competence, cache = TRUE}
# load in 71 counties with over 100 Chinese language web pages, with svm predictions 

bycounty2 <- read.csv("raw-data/predict.csv")

# Dropping all N/As 

bycounty3 <- bycounty2 %>% drop_na()

# Create a statistical summary of the linear regression model that regresses a mayor first year or last year binary indicator on  he number of competence metnions on the websites by county

# Table 3 (1)
linear_1 <- stan_glm(comp ~ mayor_first + mayor_last, data=bycounty3)  # ALMOST: mayo first yr more compolence

  # Adds county 2009 gdp per capita and proportion of county population over the age of 15 who are illiterate and number of county resident employed in information production, wholesale and retail from the 2010 census and total links found from root url of countyurl and 2009 provincial level expenditure on culture and media multiplied by the ratio of county GDP to province GDP
  
# Table 3 (2)
linear_2 <- stan_glm(comp ~ mayor_first +mayor_last +X2009_gdppc_cny+X2010_illiterateprop+itemploy + linksall+ county_mediaexp, data=bycounty3)


# Adds whether county party secretary is in first year of office; takes on value of 1 if sec_2011 = 1, 0 otherwise and whether county party secretary is in last year of office; takes on value of 1 if sec_2011 = 1, 0 otherwise
# Table 3 (3)

linear_3 <- stan_glm(comp ~ mayor_first + mayor_last + X2009_gdppc_cny + X2010_illiterateprop+itemploy + linksall+ county_mediaexp + sec_first + sec_last, data=bycounty3)


# Adds whether whether prefecture party secretary is in first or last year of office; takes on value of 1 if pref_ps_2011 = 1, 0 otherwise and evel of education of the prefecture party secretary at the end of formal schooling (not education while a government official); 6 = Doctoral degree; 5 = Master's degree; 4 = Bachelor's degree; 3 = degree from junior college; 2 = high school, 1 = lower than junior college and gdp per capita of the prefecture in 2010 

# Table 3 (4)
linear_4 <- stan_glm(comp ~ mayor_first + mayor_last + X2009_gdppc_cny + X2010_illiterateprop+itemploy + linksall+ county_mediaexp + sec_first + sec_last + pref_ps_first + pref_ps_last + pref_ps_edulevel + pref_2010_gdppc, data=bycounty3) 


# Adds mayor age, mayor gender and mayor education level

# Table 3 (5)
linear_5 <- stan_glm(comp ~ mayor_first + mayor_last + X2009_gdppc_cny + X2010_illiterateprop+itemploy + linksall+ county_mediaexp + sec_first + sec_last + pref_ps_first + pref_ps_last + pref_ps_edulevel + pref_2010_gdppc + mayor_age + mayor_gender + mayor_edulevel, data=bycounty3)


# Adds mayor promotion

# Table 3 (6)
linear_6 <- stan_glm(comp ~ mayor_first + mayor_last + X2009_gdppc_cny + X2010_illiterateprop+itemploy + linksall+ county_mediaexp + sec_first + sec_last + pref_ps_first + pref_ps_last + pref_ps_edulevel + pref_2010_gdppc + mayor_age + mayor_gender + mayor_edulevel+ mayor_promote, data=bycounty3)
```

```{r print_competence}
print(linear_1, digits = 3)
print(linear_2, digits = 3)
print(linear_3, digits = 3)
print(linear_4, digits = 3)
print(linear_5, digits = 3)
print(linear_6, digits = 3)

# Place next to original tables
```
```{r predictive_inference_competence_stargazer,  results="asis", echo=FALSE}

linear_1_st <- data.frame(linear_1)
linear_2_st <- data.frame(linear_2)
linear_3_st <- data.frame(linear_3)
linear_4_st <- data.frame(linear_4)
linear_5_st <- data.frame(linear_5)
linear_6_st <- data.frame(linear_6)

stargazer(linear_1_st, linear_2_st, linear_3_st, linear_4_st, linear_5_st, linear_6_st, # The various models included in the table
          title="Table 3: Regression Results: Competence", # The title of the table
          dep.var.caption = c("Dependent variable: Competence"), # The Caption of the table
          dep.var.labels.include=FALSE, # Don't include dependent variable labels
          no.space=TRUE, 
          keep.stat="n", # Include number of observation
          table.layout ="=l-c-t-a-s=n", # Detailing table layout according to replication paper (first dependent variable caption, then column headers, then coefficient table, then added lines, then summary statistics, then notes)
          add.lines=list(c("Resource controls",
                           rep("No", 1),rep("Yes",5)),
                        c("Peer controls",
                           rep("No", 2),rep("Yes",4)),
                        c("Prefecture controls",
                           rep("No", 3),rep("Yes",3)),
                        c("Ability controls",
                           rep("No", 4),rep("Yes",2)),
                        c("Career paths controls",
                           rep("No", 5),rep("Yes",1))), # Add lines to describe in categories the series of variables included
                        covariate.labels = c("Beginning Tenure", "End Tenure"),
                        float = FALSE) # Rename coefficient labels


# Note: Default type is Latex
```


### Benevolence

```{r regression_comparison_benevolence, cache = TRUE}
# Create a statistical summary of the linear regression model that regresses a mayor first year or last year binary indicator on  he number of competence metnions on the websites by county

# Table 3 (1)
linear.1 <- stan_glm(benev ~ mayor_first + mayor_last, data=bycounty3)  # ALMOST: mayo first yr more compolence

  # Adds county 2009 gdp per capita and proportion of county population over the age of 15 who are illiterate and number of county resident employed in information production, wholesale and retail from the 2010 census and total links found from root url of countyurl and 2009 provincial level expenditure on culture and media multiplied by the ratio of county GDP to province GDP
  
# Table 3 (2)
linear.2 <- stan_glm(benev ~ mayor_first +mayor_last +X2009_gdppc_cny+X2010_illiterateprop+itemploy + linksall+ county_mediaexp, data=bycounty3)


# Adds whether county party secretary is in first year of office; takes on value of 1 if sec_2011 = 1, 0 otherwise and whether county party secretary is in last year of office; takes on value of 1 if sec_2011 = 1, 0 otherwise
# Table 3 (3)

linear.3 <- stan_glm(benev ~ mayor_first + mayor_last + X2009_gdppc_cny + X2010_illiterateprop+itemploy + linksall+ county_mediaexp + sec_first + sec_last, data=bycounty3)


# Adds whether whether prefecture party secretary is in first or last year of office; takes on value of 1 if pref_ps_2011 = 1, 0 otherwise and evel of education of the prefecture party secretary at the end of formal schooling (not education while a government official); 6 = Doctoral degree; 5 = Master's degree; 4 = Bachelor's degree; 3 = degree from junior college; 2 = high school, 1 = lower than junior college and gdp per capita of the prefecture in 2010 

# Table 3 (4)
linear.4 <- stan_glm(benev ~ mayor_first + mayor_last + X2009_gdppc_cny + X2010_illiterateprop+itemploy + linksall+ county_mediaexp + sec_first + sec_last + pref_ps_first + pref_ps_last + pref_ps_edulevel + pref_2010_gdppc, data=bycounty3) 


# Adds mayor age, mayor gender and mayor education level

# Table 3 (5)
linear.5 <- stan_glm(benev ~ mayor_first + mayor_last + X2009_gdppc_cny + X2010_illiterateprop+itemploy + linksall+ county_mediaexp + sec_first + sec_last + pref_ps_first + pref_ps_last + pref_ps_edulevel + pref_2010_gdppc + mayor_age + mayor_gender + mayor_edulevel, data=bycounty3)


# Adds mayor promotion

# Table 3 (6)
linear.6 <- stan_glm(benev ~ mayor_first + mayor_last + X2009_gdppc_cny + X2010_illiterateprop+itemploy + linksall+ county_mediaexp + sec_first + sec_last + pref_ps_first + pref_ps_last + pref_ps_edulevel + pref_2010_gdppc + mayor_age + mayor_gender + mayor_edulevel+ mayor_promote, data=bycounty3)
```

```{r print_benevolence}
print(linear.1, digits = 3)
print(linear.2, digits = 3)
print(linear.3, digits = 3)
print(linear.4, digits = 3)
print(linear.5, digits = 3)
print(linear.6, digits = 3)

# Place next to original tables
```

In a second step I go through the various regressions seeking to understand whether any of the tested variable classes (resources, peers, prefecture, ability, career path) explain the observed phenomena better than the ones around tenure. I do so by creating a series of new regressions that include only the variables in the respective variable classes. In addition I introduce a new series of classes: culture that includes the variables macro-region and county type.

```{r new_regression_comparison_competence, cache = TRUE}

# Create a statistical summary of the linear regression model that regresses a mayor first year or last year binary indicator on  he number of competence metnions on the websites by county

  # Resources
linear_7 <- stan_glm(comp ~ X2009_gdppc_cny+X2010_illiterateprop+itemploy + linksall+ county_mediaexp, data=bycounty3)
linear.7 <- stan_glm(benev ~ X2009_gdppc_cny+X2010_illiterateprop+itemploy + linksall+ county_mediaexp, data=bycounty3)



# Peers
linear_8 <- stan_glm(comp ~ sec_first + sec_last, data=bycounty3)
linear.8 <- stan_glm(benev ~ sec_first + sec_last, data=bycounty3)


# Prefecture
linear_9 <- stan_glm(comp ~ pref_ps_first + pref_ps_last + pref_ps_edulevel + pref_2010_gdppc, data=bycounty3) 
linear.9 <- stan_glm(benev ~ pref_ps_first + pref_ps_last + pref_ps_edulevel + pref_2010_gdppc, data=bycounty3) 


# Ability
linear_10 <- stan_glm(comp ~ mayor_age + mayor_gender + mayor_edulevel, data=bycounty3)
linear.10 <- stan_glm(benev ~ mayor_age + mayor_gender + mayor_edulevel, data=bycounty3)


# Career path
linear_11 <- stan_glm(comp ~ mayor_promote, data=bycounty3)
linear.11 <- stan_glm(benev ~ mayor_promote, data=bycounty3)


# Culture
linear_12 <- stan_glm(comp ~ macroregion, data=bycounty3)
linear.12 <- stan_glm(benev ~ macroregion, data=bycounty3)

```

I then compare all the available models with the leave-one-out method to see which one of these is best suited to explain the observed phenomena.

```{r, cache = TRUE}
# Leave-one-out cross validation for all prior models
loo_1 <- loo(linear_1, k_threshold = 0.7)
loo_2 <- loo(linear_2, k_threshold = 0.7)
loo_3 <- loo(linear_3, k_threshold = 0.7)
loo_4 <- loo(linear_4, k_threshold = 0.7)
loo_5 <- loo(linear_5, k_threshold = 0.7)
loo_6 <- loo(linear_6, k_threshold = 0.7)
loo_7 <- loo(linear_7, k_threshold = 0.7)
loo_8 <- loo(linear_8, k_threshold = 0.7)
loo_9 <- loo(linear_9, k_threshold = 0.7)
loo_10 <- loo(linear_10, k_threshold = 0.7)
loo_11 <- loo(linear_11, k_threshold = 0.7)
loo_12 <- loo(linear_12, k_threshold = 0.7)

# Compare models 
loo_compare(loo_1, loo_2, loo_3, loo_4, loo_5, loo_6, loo_7, loo_8, loo_9, loo_10, loo_11, loo_12)
```

```{r, cache = TRUE}
# Leave-one-out cross validation for all prior models
loo.1 <- loo(linear.1, k_threshold = 0.7)
loo.2 <- loo(linear.2, k_threshold = 0.7)
loo.3 <- loo(linear.3, k_threshold = 0.7)
loo.4 <- loo(linear.4, k_threshold = 0.7)
loo.5 <- loo(linear.5, k_threshold = 0.7)
loo.6 <- loo(linear.6, k_threshold = 0.7)
loo.7 <- loo(linear.7, k_threshold = 0.7)
loo.8 <- loo(linear.8, k_threshold = 0.7)
loo.9 <- loo(linear.9, k_threshold = 0.7)
loo.10 <- loo(linear.10, k_threshold = 0.7)
loo.11 <- loo(linear.11, k_threshold = 0.7)
loo.12 <- loo(linear.12, k_threshold = 0.7)

# Compare models 
loo_compare(loo.1, loo.2, loo.3, loo.4, loo.5, loo.6, loo.7, loo.8, loo.9, loo.10, loo.11, loo.12)
```
The comparison suggests that the best models for how competent an official is described as, are the tenure based model employed in the paper and whether officials were promoted in the two ensuing years. The later is a post-treatment variable. Rather than delviering additional insights on what the factors around an official are that determine the website content, it suggests the relative importance of the website content in determining whether an individual is promoted. In combination this supports the hypothesis of the author that the websites have an important signalling function within the Chinese state apparatus to determine who gets promoted.

## Validating geographic split of sample

Subsequently I am simulating repeated sampling. I do so by creating a function that allows me to draw 100 and 48 random samples from the underlying countywebsites (countyweb). I repeat this step 1000 times, counting the number of counties from each province. I then compare that count with the count of counties in the paper samples (the sample of 100 and the 48 counties we actually end up constructing a model with). 

### Random sample of 100
```{r}
countyweb <- read.csv("raw-data/countywebsites.csv")
county100 <- read.csv("raw-data/countywebsites_sampled100.csv", sep="\t") # 100 counties
glimpse(bycounty3) # 48 counties for subsequent predictions

# function to draw a random samples of size 100 from countyweb and save provinces as names

x <- sample_n(countyweb, 100)

county100_sim <- function(){
  
  x <- sample_n(countyweb, 100)
  list(x$Province)
}
# Count the number of times each province occurs 

calc_provinces <- function(sample){
  
  # Given a sample --- a vector of length 100 with provinces in a random order --- how often does each province occur?
  stopifnot(is.list(sample))
  plan <- unlist(sample)
  
  stopifnot(length(plan) == 100)
  stopifnot(all(plan %in% c("Heilongjiang", "Jilin", "Liaoning", "Qinghai", "Gansu", "Shaanxi", "Shanxi", "Hebei", "Sichuan", "Hubei", "Henan", "Shandong", "Anhui", "Jiangsu", "Yunnan", "Guizhou", "Hunan", "Jiangxi", "Zhejiang", "Hainan", "Guangdong", "Fujian", "Beijing", "Tianjin", "Chongqing", "Shanghai", "Xinjiang", "Inner Mongolia", "Tibet", "Ningxia", "Guangxi")))

  provinces <- c("Heilongjiang", "Jilin", "Liaoning", "Qinghai", "Gansu", "Shaanxi", "Shanxi", "Hebei", "Sichuan", "Hubei", "Henan", "Shandong", "Anhui", "Jiangsu", "Yunnan", "Guizhou", "Hunan", "Jiangxi", "Zhejiang", "Hainan", "Guangdong", "Fujian", "Beijing", "Tianjin", "Chongqing", "Shanghai", "Xinjiang", "Inner Mongolia", "Tibet", "Ningxia", "Guangxi")
  
  provinces_count <- c(1:31)
  
  for (i in 1:31){
  provinces_count[i] <- sum(plan == provinces[i])
  }
  
  provinces_out <- data.frame(provinces, provinces_count)
  return(provinces_out)
}
```

```{r, cache = TRUE}
# Create tibble that contains a thousand repetition of the sampling  

sim <- 
  tibble(replication = 1:1000) %>% 
  mutate(sample_provinces = map(replication, ~ county100_sim())) %>%
  mutate(provinces = map(sample_provinces, ~ calc_provinces(.)))  %>%
  select(-sample_provinces)

sim_2 <- sim %>% unnest(cols = c(provinces)) 

sim_2 <- sim_2[order(sim_2$provinces),]
        
  
```

```{r}

provinces_100 <- county100 %>% group_by(province_en) %>% count()

provinces_dat <- data.frame(provinces)

provinces_100_all <- provinces_dat %>% 
                  left_join(provinces_100, by = c("provinces" = "province_en")) %>%
                  mutate(Count = ifelse(is.na(n) == TRUE, 0, n)) %>%
                  select(-n)

provinces_100_all <- provinces_100_all[order(provinces_100_all$provinces),] %>%
                    mutate(Number = 1:31)

# Create a graph 

sim_2 %>% 
  ggplot(aes(x = provinces_count, y = provinces, fill = provinces)) + 
  geom_density_ridges(rel_min_height = 0.01, scale = 2, alpha = 0.7, size = 0.3, panel_scaling = FALSE) +
  labs(title = "Distribution for frequency of counties per province in sample of 100",
         subtitle = "The geographic distribution of the sample utilized in the paper is surprising based on 1000 repeated samples",
         caption = "Data from paper: How Chinese Officials Use the Internet to Construct their Public Image",
         x = "Frequency of counties per province in sample of 100",
         y = "Provinces")+
  theme_ridges() +
  scale_fill_cyclical(values = c("blue", "green"))+
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      axis.text.x = element_text(size=10, angle = 270)
    )+
  xlim(0, 13)+
  geom_segment(data = provinces_100_all, aes(x = Count, xend = Count, y = Number, yend = Number+1), color = "red") + 
  coord_flip()
```

```{r}
# Create 95% CI intervals and check for which ones the observed frequency count is outside the 95% CI interval

sim_3 <- sim_2 %>%
  group_by(provinces) %>%
  summarize(CI_lower = quantile(provinces_count, .025),
            CI_upper = quantile(provinces_count, .975)) %>%
  left_join(provinces_100_all, by = c("provinces", "provinces")) %>%
  mutate(`Outside CI` = ifelse(Count > CI_upper | Count < CI_lower, "Yes", "No")) %>%
  select(-Number)

# Create gt table

gt_table_2 <- 
  sim_3 %>%
  gt(
    rowname_col = "Provinces",
    groupname_col = "Confidence Intervals"
  )

gt_table_2 %>% 
  tab_stubhead(label = "Provinces") %>%
  tab_header(
    title = "Extension Table 1: Frequency of provinces in sample of 100",
    subtitle = "Based on simulation of 1000 samples of 100") %>%
  cols_align("center") %>%
  cols_label(
    provinces = "Provinces",
    CI_upper = "97.5 Percentile",
    CI_lower = "2.5 Percentile",
    Count = "Frequency in paper sample"
  )
```

Repeated simulated sampling allows us to conclude that the sample of 100 in the paper is random and thereby representative in terms of geographic sampling. This is because the number of counties from a province in no case is outside the 95% CI interval that we constructed. The graph shows that in some counties, s.a. Heilongjiang or Hennan the county occurences are rather on the margins of what we would expect to see.   

### Sample of 48 for modelling

```{r}
# function to draw a random samples of size 48 from countyweb and save provinces as names

county48_sim <- function(){
  
  x48 <- sample_n(countyweb, 48)
  list(x48$Province)
}
# Count the number of times each province occurs 

calc_provinces_48 <- function(sample){
  
  # Given a sample --- a vector of length 100 with provinces in a random order --- how often does each province occur?
  stopifnot(is.list(sample))
  plan <- unlist(sample)
  
  stopifnot(length(plan) == 48)
  stopifnot(all(plan %in% c("Heilongjiang", "Jilin", "Liaoning", "Qinghai", "Gansu", "Shaanxi", "Shanxi", "Hebei", "Sichuan", "Hubei", "Henan", "Shandong", "Anhui", "Jiangsu", "Yunnan", "Guizhou", "Hunan", "Jiangxi", "Zhejiang", "Hainan", "Guangdong", "Fujian", "Beijing", "Tianjin", "Chongqing", "Shanghai", "Xinjiang", "Inner Mongolia", "Tibet", "Ningxia", "Guangxi")))

  provinces <- c("Heilongjiang", "Jilin", "Liaoning", "Qinghai", "Gansu", "Shaanxi", "Shanxi", "Hebei", "Sichuan", "Hubei", "Henan", "Shandong", "Anhui", "Jiangsu", "Yunnan", "Guizhou", "Hunan", "Jiangxi", "Zhejiang", "Hainan", "Guangdong", "Fujian", "Beijing", "Tianjin", "Chongqing", "Shanghai", "Xinjiang", "Inner Mongolia", "Tibet", "Ningxia", "Guangxi")
  
  provinces_count <- c(1:31)
  
  for (i in 1:31){
  provinces_count[i] <- sum(plan == provinces[i])
  }
  
  provinces_out <- data.frame(provinces, provinces_count)
  return(provinces_out)
}
```

```{r, cache = TRUE}
# Create tibble that contains a thousand repetition of the sampling  

sim48 <- 
  tibble(replication = 1:1000) %>% 
  mutate(sample_provinces = map(replication, ~ county48_sim())) %>%
  mutate(provinces = map(sample_provinces, ~ calc_provinces_48(.)))  %>%
  select(-sample_provinces)

sim_48_2 <- sim48 %>% unnest(cols = c(provinces)) 

sim_48_2 <- sim_48_2[order(sim_48_2$provinces),]
```

```{r}

# Count number of counties in paper sample
provinces_48 <- bycounty3 %>% group_by(province_en) %>% count()

provinces_dat_48 <- data.frame(provinces)

provinces_48_all <- provinces_dat_48 %>% 
                  left_join(provinces_48, by = c("provinces" = "province_en")) %>%
                  mutate(Count = ifelse(is.na(n) == TRUE, 0, n)) %>%
                  select(-n)

provinces_48_all <- provinces_48_all[order(provinces_48_all$provinces),] %>%
                    mutate(Number = 1:31)

# Create a graph 

sim_48_2 %>% 
  ggplot(aes(x = provinces_count, y = provinces, fill = provinces)) + 
  geom_density_ridges(rel_min_height = 0.01, scale = 2, alpha = 0.7, size = 0.3, panel_scaling = FALSE) +
  labs(title = "Distribution for frequency of counties per province in sample of 48",
         subtitle = "The geographic distribution of the sample utilized in the paper is surprising based on 1000 repeated samples",
         caption = "Data from paper: How Chinese Officials Use the Internet to Construct their Public Image",
         x = "Frequency of counties per province in sample of 48",
         y = "Provinces")+
  theme_ridges() +
  scale_fill_cyclical(values = c("blue", "green"))+
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      axis.text.x = element_text(size=10, angle = 270)
    )+
  xlim(0, 13)+
  geom_segment(data = provinces_48_all, aes(x = Count, xend = Count, y = Number, yend = Number+1), color = "red") + 
  coord_flip()
```

```{r}
# Create 95% CI intervals and check for which ones the observed frequency count is outside the 95% CI interval

sim_48_3 <- sim_48_2 %>%
  group_by(provinces) %>%
  summarize(CI_lower = quantile(provinces_count, .025),
            CI_upper = quantile(provinces_count, .975)) %>%
  left_join(provinces_48_all, by = c("provinces", "provinces")) %>%
  mutate(`Outside CI` = ifelse(Count > CI_upper | Count < CI_lower, "Yes", "No"),
         `On lower CI boundary` = ifelse(Count == CI_lower, "Yes", "No")) %>%
  select(-Number)

# Create gt table

gt_table_3 <- 
  sim_48_3 %>%
  gt(
    rowname_col = "Provinces",
    groupname_col = "Confidence Intervals"
  )

gt_table_3 %>% 
  tab_stubhead(label = "Provinces") %>%
  tab_header(
    title = "Extension Table 1: Frequency of provinces in sample of 48",
    subtitle = "Based on simulation of 1000 samples of 48") %>%
  cols_align("center") %>%
  cols_label(
    provinces = "Provinces",
    CI_upper = "97.5 Percentile",
    CI_lower = "2.5 Percentile",
    Count = "Frequency in paper sample"
  )
```

Repeated simulated sampling allows us to conclude that the sample of 48 in the paper is likely random and thereby representative in terms of geographic sampling. This is because the number of counties from a province in only one case (Zhejiang) is outside the 95% CI interval that we constructed. The graph shows that there is a surprising amount of states at the lower boundary of 0. This seems plausible due to the small size of the sample (Beijing, Hainan, Henan, Jilin, Liaoning, Ningxia, Qinghai and Tibet). There seems to be no regional pattern among these states (3 East, 2 Central, 3 West).

